/*
 * An example of using the GPars library for parallelism.
 *
 * This example uses the GPars Dataflow to ensure each service in a pipeline
 * is kept as busy as possible.
 */
import util.DataSourceIterator
import util.ServiceProvider
@Grab(group='org.codehaus.gpars', module='gpars', version='1.1.0')
import groovyx.gpars.*
import groovyx.gpars.dataflow.*

// Object passed along the Dataflow. We wrap a Data object in a Packet so we can
// pass metadata along with it.
class Packet {
	Data data // The data being worked on.
	File file // Where the result will be written.
	String key // The MASC index key of the original document.
}


include 'Servers'
include 'Common'

def datasource = Datasource {
	server servers.localhost
	name 'picard:masc.text_1.3.0'
}

String[] keys = datasource.list()

// These are the common services between the two providers we want to invoke.
def services = [ 'tokenizer', 'splitter', 'tagger', 'ner' ]

// Get the service clients.
def provider = new ServiceProvider(servers.default, 'gate', '1.3.1', services)

// Create directories for the output.
File destination = createDir('/Users/suderman/Projects/LAPPS/output/gate')

// Fetch a document from the datasource.
def reader = { packet ->
	println "Getting data for key ${packet.key}"
	packet.data = datasource.get(packet.key)
	return packet
}

// Execute the service on the data in the packet.
def execute = { service, packet ->
	if (packet.data == null) {
		println "Packet data is NULL!"
		return packet
	}
	if (packet.data.discriminator == Types.ERROR) {
		println "Error encountered. Skipping ${service.endpoint}"
		println packet.data.payload
		return packet
	}
	println "Running ${service.endpoint} ${packet.key}"
	packet.data = service.execute(packet.data)
	return packet
}

def tokenizer = execute.curry(gate.tokenizer)
def splitter = execute.curry(gate.splitter)
def tagger = execute.curry(gate.splitter)
def ner = execute.curry(gate.ner)

def writer = { packet ->
	println "Writing ${packet.file.path}"
	packet.file.text = packet.data.payload
	return packet
}

GParsPool.withPool {
	
	def queue = new DataflowQueue()
	DataflowReadChannel channel = queue | reader | tokenizer | splitter | ner | writer
		
	
	String lastKey = null
	keys[0..9].each { key ->		
		queue << new Packet(key:key)
		lastKey = key
	} 
	println "The last key is ${lastKey}"
	
	while (channel.val.key != lastKey) { sleep(250) }
}
println "Done."

